{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute 4He form factors from 1-body densities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gvar as gv\n",
    "import lsqfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(fit, subs=True):\n",
    "    \"\"\"Parses the fit function and posteriror to latex label.\n",
    "    \n",
    "    If subs = False, don't substitude in posterior parameters.\n",
    "    \"\"\"\n",
    "    expressions = {}\n",
    "    values = {}\n",
    "    for key, val in fit.p.items():\n",
    "        if hasattr(val, \"__iter__\"):\n",
    "            expr = sympy.symbols(\" \".join([f\"{key}{n}\" for n, el in enumerate(val)]))\n",
    "        else:\n",
    "            expr = sympy.Symbol(key)\n",
    "\n",
    "        expressions[key] = expr\n",
    "\n",
    "        if hasattr(expr, \"__iter__\"):\n",
    "            for ee, vv in zip(expr, val):\n",
    "                values[sympy.latex(ee)] = vv\n",
    "        else:\n",
    "            values[sympy.latex(expr)] = val\n",
    "\n",
    "    f_expr = fit.fcn(\n",
    "        x=sympy.Symbol(\"x\"), p={key: expr for key, expr in expressions.items()}\n",
    "    )\n",
    "\n",
    "    s = sympy.latex(f_expr)\n",
    "    if subs:\n",
    "        for pat, sub in values.items():\n",
    "            s = s.replace(pat, str(sub))\n",
    "            s = re.sub(r\"e\\+?([\\-]?)[0]*([0-9]+)\", \" 10^{\\g<1>\\g<2>}\", s)\n",
    "    return re.sub(r\"\\+\\s+\\-\", \"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = sns.color_palette(\"hls\", 8)\n",
    "\n",
    "\n",
    "def plot_fit(\n",
    "    fit: lsqfit.nonlinear_fit,\n",
    "    ax: Optional[plt.Axes] = None,\n",
    "    color=None,\n",
    "    label=None,\n",
    "    plot_data: bool = True,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Plots a nonlinear_fit (data and fit result).\"\"\"\n",
    "    _, ax = plt.subplots(figsize=(3, 2), dpi=300) if not ax else (None, ax)\n",
    "\n",
    "    y_mean, y_sdev = gv.mean(fit.data[1]), gv.sdev(fit.data[1])\n",
    "    if plot_data:\n",
    "        ax.errorbar(\n",
    "            fit.data[0],\n",
    "            y_mean,\n",
    "            y_sdev,\n",
    "            marker=\"o\",\n",
    "            ms=2,\n",
    "            ls=\"None\",\n",
    "            capsize=2,\n",
    "            elinewidth=1,\n",
    "            label=\"data\",\n",
    "            color=COLORS[0],\n",
    "        )\n",
    "\n",
    "    x_int = np.linspace(fit.data[0].min(), fit.data[0].max())\n",
    "    y_fit = fit.fcn(x_int, fit.p)\n",
    "    y_mean, y_sdev = gv.mean(y_fit), gv.sdev(y_fit)\n",
    "\n",
    "    try:\n",
    "        llabel = parse_label(fit)\n",
    "        llabel = f\"$f(x) = {label}$\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        llabel = str(fit.p)\n",
    "\n",
    "    ax.fill_between(\n",
    "        x_int,\n",
    "        y_mean - y_sdev,\n",
    "        y_mean + y_sdev,\n",
    "        color=color or COLORS[1],\n",
    "        alpha=0.5,\n",
    "        label=label or \"fit\",\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        fancybox=False, frameon=False, bbox_to_anchor=(1.1, 0.5), loc=\"center left\"\n",
    "    )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions (needs user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBARC = 197.3269804\n",
    "MN = 938.918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this code to run, you have to specify two directories:\n",
    "    \n",
    "1. `DATA_4HE_AV18`  which contains the `compton-dens-4he-av18-...-rho1b.dat`  files\n",
    "2. `DATA_FF` which contains the single proton & neutron form factor data as specified in [[1707.09063]](https://arxiv.org/abs/1707.09063 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/home/ckoerber/data\"\n",
    "DATA_4HE_CHSMS = \"/home/ckoerber/data/nuc/4he/chsms\"\n",
    "\n",
    "DENSITIES = [\n",
    "    f for f in os.listdir(DATA_4HE_CHSMS) if f.endswith(\".dat\") and \"th=1.80E+02\" in f\n",
    "]\n",
    "print(\"First rho1b file\", DENSITIES[0])\n",
    "\n",
    "DATA_FF = \"/home/ckoerber/data/nuc/NucleonFFData\"\n",
    "print(\"\\nFF data:\", os.listdir(DATA_FF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse file names to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = (\n",
    "    r\"compton-dens-(?P<nuc>[0-9A-z]+)\",\n",
    "    r\"\\-(?P<potential>[a-z0-9\\+]+)\",\n",
    "    r\"\\-(?P<order>[a-z0-9\\+]+)\",\n",
    "    r\"\\-cut=(?P<cut>[0-9]+)\",\n",
    "    r\"\\-(?P<empot>[a-zA-Z]+)\",\n",
    "    r\"\\-(?P<cmpi>(?:[a-z0-9]+))\",\n",
    "    r\"\\-Lam=(?P<Lam>(?:[\\.0-9]+))\",\n",
    "    r\"\\-c1=(?P<c1>(?:[\\-\\.0-9]+))\",\n",
    "    r\"\\-c3=(?P<c3>(?:[\\-\\.0-9]+))\",\n",
    "    r\"\\-c4=(?P<c4>(?:[\\-\\.0-9]+))\",\n",
    "    r\"\\-Lamnum=(?P<lambda>(?:[0-9\\.e\\+]+))\",\n",
    "    r\"\\-tnfcut=(?P<tnfcut>(?:[0-9]+))\",\n",
    "    r\"\\-om=(?P<omega>(?:[0-9\\.]+E[\\+\\-][0-9]+))\",\n",
    "    r\"\\-th=(?P<theta>(?:[0-9\\.E\\+]+))\",\n",
    "    r\"\\-nx=(?P<nx>(?:[0-9]+))\",\n",
    "    r\"\\-nphi=(?P<nphi>(?:[0-9]+))\",\n",
    "    r\"\\-np12\\=np34\\=(?P<np12_np34>(?:[0-9\\+]+))\",\n",
    "    r\"\\-np3\\=(?P<np3>(?:[0-9\\+]+))\",\n",
    "    r\"\\-nq4\\=nq=(?P<nq4_nq>(?:[0-9\\+]+))\",\n",
    "    r\"\\-j12max=(?P<j12max>(?:[0-9]+))\",\n",
    "    r\"\\-lmax=(?P<lmax>(?:[0-9]+))\",\n",
    "    r\"\\-lsummax=(?P<lsummax>(?:[0-9]+))\",\n",
    "    r\"\\-tau4max=(?P<tau4max>(?:[0-9]+))\",\n",
    "    r\"\\-rho1b\\.dat\",\n",
    ")\n",
    "ppat = \"\"\n",
    "data = None\n",
    "for pat in patterns:\n",
    "    ppat += pat\n",
    "    match = re.search(ppat, DENSITIES[0])\n",
    "    if not match:\n",
    "        print(data)\n",
    "        raise ValueError(ppat)\n",
    "    else:\n",
    "        data = match.groupdict()\n",
    "pattern = re.compile(\"\".join(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    int: [\"nx\", \"nphi\", \"j12max\", \"lmax\", \"lsummax\", \"tau4max\"],\n",
    "    float: [\"lambda\", \"omega\", \"theta\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pattern.search(f).groupdict() for f in DENSITIES]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.describe().T)\n",
    "\n",
    "for dtype, cols in dtypes.items():\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "\n",
    "df[\"file\"] = DENSITIES\n",
    "df = df.sort_values(\"omega\").reset_index(drop=True)\n",
    "df[\"q\"] = df[\"omega\"] / HBARC * 2\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only varying quantities are omega and theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The routines below parse the `rho1b` files.\n",
    "\n",
    "Results are dictionaries with keys specifying the matrix elements and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = r\"MAXRHO1BINDEX\\s+\\=\\s+(?P<max_rho_index>[0-9]+)\"\n",
    "pp += r\".*\"\n",
    "pp += r\"RHO1BINDX\\s+\\=(?P<rho_index>[0-9\\*\\,\\-\\s]+)\"\n",
    "pp += r\".*\"\n",
    "pp += r\"\\/\\s+(?P<om_theta>[0-9\\.\\-\\+E ]+\\n)\"\n",
    "pp += r\"\\s+(?P<rho>[0-9\\.\\-\\+E\\s]+\\n)\"\n",
    "\n",
    "\n",
    "def parse_fortran_funny(string):\n",
    "    \"\"\"Converts fortran format arrys in file to python objects\"\"\"\n",
    "    for pat, subs in {\n",
    "        f\"{key}*{val}\": \", \".join([val] * int(key))\n",
    "        for key, val in set(\n",
    "            re.findall(r\"([0-9]+)\\*([\\-0-9]+)\", re.sub(r\"\\s+\", \" \", string))\n",
    "        )\n",
    "    }.items():\n",
    "        string = string.replace(pat, subs)\n",
    "\n",
    "    arr = np.array(list(map(int, string.split(\",\"))))\n",
    "    nd = len(arr) // 8\n",
    "    return pd.DataFrame(\n",
    "        data=arr.reshape([nd, 8]),\n",
    "        columns=[\n",
    "            \"ms3_x2\",\n",
    "            \"mt3_x2\",\n",
    "            \"mjtot_x2\",\n",
    "            \"ms3p_x2\",\n",
    "            \"mt3p_x2\",\n",
    "            \"mjtotp_x2\",\n",
    "            \"k\",\n",
    "            \"bk\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "parse = {\n",
    "    \"max_rho_index\": int,\n",
    "    \"om_theta\": lambda el: np.array([float(ee) for ee in el.split(\" \") if ee]),\n",
    "    \"rho\": lambda el: np.array([float(ee) for ee in el.split(\" \") if ee]),\n",
    "    \"rho_index\": parse_fortran_funny,\n",
    "}\n",
    "\n",
    "\n",
    "def parse_1bd(address):\n",
    "    \"\"\"Reads in one-body density files\"\"\"\n",
    "    with open(address, \"r\") as inp:\n",
    "        t = inp.read()\n",
    "    dd = re.search(pp, t, re.MULTILINE | re.DOTALL).groupdict()\n",
    "    for key, val in parse.items():\n",
    "        dd[key] = val(dd[key])\n",
    "\n",
    "    channels = dd[\"rho_index\"]\n",
    "    channels[\"rho\"] = dd[\"rho\"]\n",
    "    dd[\"channels\"] = channels\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df.query(\"omega == 0\").file.values[0]\n",
    "dens = parse_1bd(os.path.join(DATA_4HE_CHSMS, f))\n",
    "\n",
    "print(\"Dictionary keys are:\", dens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens[\"channels\"].sort_values(\"rho\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries `k` and `bk` encode angular dependence of the one-body operator\n",
    "$$\n",
    "O_{1} ( \\vec k_{1} \\  \\mu' \\mu \\   \\nu  \\  \\vec k ' \\vec k ) \\equiv \\sum_{K=0}^{1}\\sum_{\\kappa=-K}^{K} \\sqrt{\\frac{4\\pi}{2K+1}} \\, k_{1}^{K} \\, Y_{K\\kappa}(\\hat k_{1})\n",
    "\\tilde O_{1} ( K \\kappa \\  \\mu' \\mu \\   \\nu  \\  \\vec k ' \\vec k )\n",
    "$$\n",
    "This would suggest, for the identity operation, $k = b_k = 0$.\n",
    "\n",
    "*Question:*\n",
    "Is this the same $k_1$ which appears in the SO force? If so, I don't have to evaluate 2b ops to get the SO done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_QUERY = (\n",
    "    \"k == bk == 0\"\n",
    "    \" and mt3_x2 == mt3p_x2\"\n",
    "    \" and mjtot_x2 == mjtotp_x2\"\n",
    "    \" and ms3_x2 == ms3p_x2\"\n",
    ")\n",
    "\n",
    "norm = dens[\"channels\"].query(IDX_QUERY)[\"rho\"].sum()\n",
    "print(\"norm (k==0==bk):\", norm)\n",
    "print(\"other contributions:\", dens[\"channels\"][\"rho\"].sum() - norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_norm(data, ms3_x2=None):\n",
    "    \"\"\"Computes the norm of 1-body density given density data\"\"\"\n",
    "    qquery = IDX_QUERY + \" and ms3_x2 == @ms3_x2\" if ms3_x2 is not None else IDX_QUERY\n",
    "    return data[\"channels\"].query(qquery)[\"rho\"].sum()\n",
    "\n",
    "\n",
    "def compute_norm_from_file(ff, data=DATA_4HE_CHSMS, ms3_x2=None):\n",
    "    \"\"\"Computes the norm of 1-body density given density file\"\"\"\n",
    "    dd = parse_1bd(os.path.join(data, ff))\n",
    "    return compute_norm(dd, ms3_x2=ms3_x2)\n",
    "\n",
    "\n",
    "print(\"norm:\", compute_norm(dens))\n",
    "print(\"norm-p:\", compute_norm(dens, ms3_x2=1))\n",
    "print(\"norm-n:\", compute_norm(dens, ms3_x2=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in GE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dipole_FF(q2):\n",
    "    \"\"\"Returns dipole form factor named GD in notes.\n",
    "    \n",
    "    Here, q2 is in GeV**2\"\"\"\n",
    "    return 1 / (1 + q2 / (0.71)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "gp_data = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(DATA_FF, \"proton_baseline_sep272019_RE8414.dat\"), sep=\"\\s+\",\n",
    "    )\n",
    "    .set_index(\"Q2\")\n",
    "    .rename(columns={\"GEp/GD\": \"gep\", \"GMp/muGD\": \"gmp\"})[[\"gep\", \"gmp\"]]\n",
    ")\n",
    "\n",
    "# Mutliply by GD\n",
    "gp_data[\"gep\"] *= dipole_FF(gp_data.index.values)\n",
    "gp_data[\"gmp\"] *= dipole_FF(gp_data.index.values)\n",
    "\n",
    "# convert q2 to MeV**2\n",
    "gp_data.index = gp_data.index * 1000 ** 2\n",
    "\n",
    "# Interpolate\n",
    "gep = interp1d(gp_data.index, gp_data.gep.values, kind=\"cubic\")\n",
    "gmp = interp1d(gp_data.index, gp_data.gmp.values, kind=\"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "gn_data = (\n",
    "    pd.read_csv(os.path.join(DATA_FF, \"Ye2017gyb_neutron_lookup.dat\"), sep=\"\\s+\",)\n",
    "    .set_index(\"Q2\")\n",
    "    .rename(columns={\"GEn/GD\": \"gen\", \"GMn/muGD\": \"gmn\"})[[\"gen\", \"gmn\"]]\n",
    ")\n",
    "\n",
    "# Mutliply by GD\n",
    "gn_data[\"gen\"] *= dipole_FF(gp_data.index.values)\n",
    "gn_data[\"gmn\"] *= dipole_FF(gp_data.index.values)\n",
    "\n",
    "# convert q2 to MeV**2\n",
    "gn_data.index = gn_data.index * 1000 ** 2\n",
    "\n",
    "# Interpolate\n",
    "gen = interp1d(gn_data.index, gn_data.gen.values, kind=\"cubic\")\n",
    "gmn = interp1d(gn_data.index, gn_data.gmn.values, kind=\"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gp_data.plot(y=\"gep\")\n",
    "gp_data.plot(y=\"gmp\", ax=ax)\n",
    "gn_data.plot(y=\"gen\", ax=ax)\n",
    "gn_data.plot(y=\"gmn\", ax=ax)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ge_correction(k2, rho, mt3_x2):\n",
    "    \"\"\"Computes - k^2/8/MN * GE(k^2)\n",
    "    \n",
    "    k^2 is in MeV^2\n",
    "    \"\"\"\n",
    "    gep_k2, gen_k2 = gep(k2), gen(k2)\n",
    "    #return (-k2 / 8 / MN ** 2 * np.where(mt3_x2 == 1, gep_k2, gen_k2) * rho).sum()\n",
    "    return (-k2 / 8 / MN ** 2 * rho).sum()\n",
    "\n",
    "\n",
    "def compute_ge_correction_norm_from_file(ff, data=DATA_4HE_CHSMS):\n",
    "    \"\"\"Computes the GE correction given a density file\n",
    "    \"\"\"\n",
    "    dd = parse_1bd(os.path.join(data, ff))\n",
    "    tmp = dd[\"channels\"].query(IDX_QUERY)\n",
    "    rho = tmp[\"rho\"].values\n",
    "    mt3_x2 = tmp[\"mt3_x2\"].values\n",
    "    q2 = (dd[\"om_theta\"][0] * HBARC * 2) ** 2\n",
    "    if q2 < gp_data.index.min():\n",
    "        q2 = gp_data.index.min()  # Avoid FF interpolation range issues\n",
    "    return ge_correction(q2, rho, mt3_x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"norm\"] = df.file.apply(compute_norm_from_file)\n",
    "df[\"norm_p\"] = df.file.apply(compute_norm_from_file, ms3_x2=1)\n",
    "df[\"k2_correction\"] = df.file.apply(compute_ge_correction_norm_from_file)\n",
    "df.drop(columns=[\"lambda\", \"tnfcut\", \"file\"]).sort_values(\"omega\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare plots & fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qquery = {\"theta\": 180, \"nuc\": \"'4he'\", \"potential\": \"'chsms'\", \"Lam\": \"'550.000'\"}\n",
    "ddf = df.query(\" and \".join(f\"{key} == {val}\" for key, val in qquery.items()))[\n",
    "    [\"q\", \"omega\", \"norm\", \"norm_p\", \"k2_correction\"]\n",
    "].sort_values(\"omega\")\n",
    "ddf = ddf.set_index(\"q\")\n",
    "print(ddf[[\"norm\", \"k2_correction\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitArgs:\n",
    "    def __init__(self, x, y, n_poly):\n",
    "        self.n_poly = n_poly\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    @staticmethod\n",
    "    def poly_x2(x, p):\n",
    "        \"\"\"Computes $f(x) = 1 - \\sum_{n=0} c_n x^{2n + 2}$.\n",
    "\n",
    "        The prior p must contain the array c.\n",
    "        \"\"\"\n",
    "        res = 1\n",
    "        if hasattr(p[\"c\"], \"__iter__\"):\n",
    "            for n, cn in enumerate(p[\"c\"]):\n",
    "                res += x ** (2 * n + 2) * cn\n",
    "        else:\n",
    "            res += x ** (2) * p[\"c\"]\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def prior(self):\n",
    "        return {\"c\": gv.gvar(-np.ones(self.n_poly), 1 + np.arange(self.n_poly))}\n",
    "\n",
    "    def __call__(self, z):\n",
    "        dy = self.y * z\n",
    "        newy = gv.gvar(self.y, dy)\n",
    "        return dict(data=(self.x, newy), fcn=self.poly_x2, prior=self.prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = ddf.loc[:0.2]\n",
    "x = tmp.index.values\n",
    "y = tmp.norm.values / tmp.norm.values[0]\n",
    "\n",
    "\n",
    "get_fit_args = FitArgs(x, y, n_poly=2)\n",
    "\n",
    "# Compute posterior\n",
    "fit, dy = lsqfit.empbayes_fit(1.0e-2, get_fit_args)\n",
    "\n",
    "print(\"Nucleus\")\n",
    "print(qquery)\n",
    "\n",
    "print(\"Numerical error of data (emperical bayes):\", dy)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(dpi=300, figsize=(3, 2))\n",
    "\n",
    "for n_poly in range(1, 5):\n",
    "    get_fit_args.n_poly = n_poly\n",
    "    fit = lsqfit.nonlinear_fit(**get_fit_args(dy))\n",
    "\n",
    "    print(\"\\n fit function:\", parse_label(fit, subs=False), \"\\n\")\n",
    "    print(fit.format(maxline=None))\n",
    "    print(\"r0 = sqrt(-6*c1) * hbarc :\", gv.sqrt(-fit.p[\"c\"][0] * 6), \"fm\")\n",
    "\n",
    "    plot_fit(\n",
    "        fit,\n",
    "        ax=ax,\n",
    "        label=fr\"$\\chi^2 = {fit.chi2/fit.dof:1.1f}$ | $f(x) = {parse_label(fit, subs=True)}$\",\n",
    "        plot_data=n_poly == 1,\n",
    "        color=COLORS[n_poly + 1],\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(\"$F(q^2)$\")\n",
    "ax.set_title(\n",
    "    \", \".join([f\"{k}={v}\" for k, v in qquery.items()]) + f\", $\\Delta y = {dy:1.1e}$\",\n",
    "    size=4,\n",
    ")\n",
    "ax.legend(loc=\"best\", fontsize=4, frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"$q$ [fm$^{-1}$]\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"multi-poly-fit.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin Orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implements\n",
    "\n",
    "$$ \\frac{i}{m_N^2} \\vec{\\sigma}_1 \\cdot ( \\vec q \\times \\vec k_1) $$\n",
    "\n",
    "where $k_1 = (\\vec p_{1i} + \\vec p_{1o})/2$ (in and out going first nucleon momentum) and $\\vec q$ the external current momenutm.\n",
    "\n",
    "Using momentum conservation $N(\\vec p_{1i}) + J(\\vec q) \\to N(\\vec p_{1o})$, this becomes\n",
    "$$\n",
    "\\frac{i}{m_N^2} \\vec{\\sigma}_1 \\cdot ( \\vec q \\times \\vec p_{1i}) \n",
    "\\to\n",
    "\\frac{i}{m_N^2} \\sum_{K=1}^1 \\sum_{\\kappa=+1, -1} \\sqrt{\\frac{4 \\pi}{2K + 1}} p_{1i} Y_{K \\kappa}(\\vec p_{1i})\n",
    "O_{K \\kappa m_{so}, m_{si}, m_t}(\\vec q)\n",
    "$$\n",
    "with\n",
    "$$\n",
    "   O_{1 \\kappa m_{so}, m_{si}, m_t}(\\vec q)\n",
    "   =\n",
    "   \\frac{\\sqrt{2} q}{m_N^2}\n",
    "$$\n",
    "for $\\vec q = q \\vec e_z$ if $m_t$ and $m_j$ is conserved and $m_{si} \\neq m_{so} = \\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spin_orbit(row, q):\n",
    "    \"\"\"in ifm**2\n",
    "    \n",
    "    density normalization?\n",
    "    \"\"\"\n",
    "    mN = MN / HBARC\n",
    "    fact = np.sqrt(2) * q / mN**2\n",
    "    out = 0\n",
    "    if (\n",
    "        row[\"mt3_x2\"] == row[\"mt3p_x2\"]\n",
    "        and row[\"mjtot_x2\"] == row[\"mjtotp_x2\"]\n",
    "        and row[\"bk\"] == 1\n",
    "        and abs(row[\"k\"]) == 1\n",
    "        and row[\"ms3_x2\"] == -row[\"ms3p_x2\"]\n",
    "        and row[\"ms3_x2\"] == row[\"k\"]\n",
    "    ):\n",
    "        out = fact * row[\"rho\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_so_from_file(ff, data=DATA_4HE_CHSMS):\n",
    "    \"\"\"Computes the GE correction given a density file\n",
    "    \"\"\"\n",
    "    dd = parse_1bd(os.path.join(data, ff))\n",
    "    qval = dd[\"om_theta\"][2] # in ifm\n",
    "    return dd[\"channels\"].apply(spin_orbit, axis=1, args=(qval,)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"spin_orbit\"] = df.file.apply(compute_so_from_file)\n",
    "qquery = {\"theta\": 180, \"nuc\": \"'4he'\", \"potential\": \"'chsms'\", \"Lam\": \"'550.000'\"}\n",
    "ddf = df.query(\" and \".join(f\"{key} == {val}\" for key, val in qquery.items()))[\n",
    "    [\"q\", \"omega\", \"norm\", \"norm_p\", \"k2_correction\", \"spin_orbit\"]\n",
    "].sort_values(\"omega\")\n",
    "ddf = ddf.set_index(\"q\")\n",
    "ddf[[\"norm\", \"k2_correction\", \"spin_orbit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300, figsize=(3, 2))\n",
    "\n",
    "ddf[[\"k2_correction\", \"spin_orbit\"]].plot(ax=ax, ls=\"--\", marker=\"o\", lw=1, ms=3)\n",
    "ax.set_ylabel(\"$F(q^2)$\")\n",
    "ax.legend(loc=\"best\", fontsize=4, frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"$q$ [fm$^{-1}$]\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"one-nucleon-corrections.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpwd",
   "language": "python",
   "name": "numpwd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
